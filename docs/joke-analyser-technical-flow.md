# AIJokeAnalyzer - Szczeg√≥≈Çowy Opis Techniczny

**Data:** 2025-11-14  
**Autor:** Claude Sonnet 4.5 + Piotras  
**Status:** üìù Dokumentacja techniczna  
**Jira:** [WL-106](https://octadecimal.atlassian.net/browse/WL-106)

---

## üìã Spis tre≈õci

1. [PrzeglƒÖd architektury](#przeglƒÖd-architektury)
2. [Flow procesu analizy](#flow-procesu-analizy)
3. [Szczeg√≥≈Çy implementacji ka≈ºdej teorii](#szczeg√≥≈Çy-implementacji-ka≈ºdej-teorii)
4. [Scoring i agregacja](#scoring-i-agregacja)
5. [Przyk≈Çadowa analiza krok po kroku](#przyk≈Çadowa-analiza-krok-po-kroku)

---

## üèóÔ∏è PrzeglƒÖd architektury

### Komponenty

```
JokeAnalyzer (g≈Ç√≥wny orchestrator)
‚îú‚îÄ‚îÄ SetupPunchlineAnalyzer      (1/9)
‚îú‚îÄ‚îÄ IncongruityAnalyzer          (2/9)
‚îú‚îÄ‚îÄ SemanticShiftAnalyzer        (3/9)
‚îú‚îÄ‚îÄ TimingAnalyzer               (4/9)
‚îú‚îÄ‚îÄ AbsurdEscalationAnalyzer     (5/9)
‚îú‚îÄ‚îÄ PsychoanalysisAnalyzer       (6/9)
‚îú‚îÄ‚îÄ ArchetypeAnalyzer            (7/9)
‚îú‚îÄ‚îÄ HumorAtomsAnalyzer           (8/9)
‚îî‚îÄ‚îÄ ReverseEngineeringAnalyzer   (9/9)
```

### Technologie

- **NLP:** spaCy 3.7+ z modelem `pl_core_news_lg` (Polish)
- **Pattern Matching:** Regex + keyword detection
- **NO AI/LLM** - Wszystko bazuje na heurystykach i NLP
- **Language:** Python 3.12+

### Model danych wej≈õciowych

```python
class AnalyzeRequest:
    joke_text: str           # Tekst ≈ºartu
    context: Optional[str]   # Dodatkowy kontekst
```

### Model danych wyj≈õciowych

```python
class AnalyzeResponse:
    overall_score: float                    # 0-10 (≈õrednia wa≈ºona)
    theory_scores: Dict[str, TheoryScore]   # 9 teorii
    suggestions: List[str]                  # Sugestie poprawy
    segment_scores: Dict[str, float]        # Reach, viral, monetization
```

```python
class TheoryScore:
    score: float              # 0-10
    explanation: str          # Dlaczego taki score?
    key_elements: List[str]   # Znalezione elementy
```

---

## üîÑ Flow procesu analizy

### High-level flow

```
INPUT: joke_text
  ‚Üì
1. Preprocessing (spaCy tokenization, POS tagging)
  ‚Üì
2. Parallel analysis przez 9 teorii
  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì
  Theory 1-9 analyzers
  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì  ‚Üì
3. Agregacja scores (weighted average)
  ‚Üì
4. Segment scoring (reach, viral, monetization)
  ‚Üì
5. Suggestions generation
  ‚Üì
OUTPUT: AnalyzeResponse
```

### Krok 1: Preprocessing

**Nie ma osobnego kroku** - ka≈ºdy analyzer robi w≈Çasny preprocessing u≈ºywajƒÖc spaCy.

**Typowy preprocessing w analyzer:**

```python
def analyze(self, joke_text: str, context: Optional[str] = None):
    # 1. Load spaCy model
    nlp = spacy.load('pl_core_news_lg')
    
    # 2. Process text
    doc = nlp(joke_text)
    
    # 3. Extract linguistic features
    tokens = [token.text for token in doc]
    pos_tags = [token.pos_ for token in doc]
    lemmas = [token.lemma_ for token in doc]
    sentences = list(doc.sents)
    
    # 4. Run theory-specific analysis
    # ... (ka≈ºdy analyzer ma w≈ÇasnƒÖ logikƒô)
    
    return {
        'score': 0.0-10.0,
        'explanation': "...",
        'key_elements': [...]
    }
```

### Krok 2: Parallel analysis (9 teorii)

Ka≈ºdy analyzer dzia≈Ça **niezale≈ºnie** i zwraca:
- `score` (0-10)
- `explanation` (tekst)
- `key_elements` (lista znalezionych element√≥w)

**BRAK AI/LLM** - wszystko bazuje na:
- Regex patterns
- Keyword matching
- NLP features (POS tags, dependencies, entities)
- Heurystyki (d≈Çugo≈õƒá, interpunkcja, emoji, etc.)

---

## üìä Szczeg√≥≈Çy implementacji ka≈ºdej teorii

### 1. Setup-Punchline Analyzer

**Cel:** Wykryƒá strukturƒô setup ‚Üí punchline

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    sentences = list(doc.sents)
    
    score = 0.0
    key_elements = []
    
    # A. Czy sƒÖ 2+ zdania?
    if len(sentences) >= 2:
        score += 3.0
        key_elements.append(f"Multiple sentences: {len(sentences)}")
    
    # B. Czy jest separator? (? ! ... --)
    if '?' in joke_text or '!' in joke_text:
        score += 2.0
        key_elements.append("Question/exclamation separator")
    
    # C. Czy ostatnie zdanie jest kr√≥tsze? (punchline)
    if len(sentences) >= 2:
        last_sent = str(sentences[-1])
        prev_sent = str(sentences[-2])
        if len(last_sent) < len(prev_sent) * 0.7:
            score += 2.5
            key_elements.append(f"Short punchline: {len(last_sent)} chars")
    
    # D. Czy sƒÖ contrast words? (ale, jednak, niestety)
    contrast_words = ['ale', 'jednak', 'niestety', 'co', 'tylko']
    for word in contrast_words:
        if word in joke_text.lower():
            score += 0.5
            key_elements.append(f"Contrast word: {word}")
    
    # E. Czy ko≈Ñczy siƒô emoji/wykrzyknikiem?
    if joke_text.strip()[-1] in ['üòÇ', 'üòÖ', 'ü§£', '!', '?']:
        score += 1.0
        key_elements.append("Punchline marker at end")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Setup-punchline structure detected: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Markers szukane:**
- Multiple sentences (2+)
- Question/exclamation separators
- Short punchline (< 70% prev sentence)
- Contrast words (ale, jednak, co)
- Emoji/punctuation at end

**Wagi:**
- Base structure: 3.0
- Separator: 2.0
- Short punchline: 2.5
- Contrast words: 0.5 each
- End marker: 1.0

---

### 2. Incongruity Analyzer

**Cel:** Wykryƒá niesp√≥jno≈õƒá, niepasujƒÖce elementy

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    
    score = 0.0
    key_elements = []
    
    # A. Tech + human emotions (AI + by≈Ça, bot + mi≈Ço≈õƒá)
    tech_words = ['ai', 'bot', 'algorytm', 'api', 'kod', 'robot']
    emotion_words = ['by≈Ça', 'mi≈Ço≈õƒá', 'serce', 'uczucia', 'romans']
    
    has_tech = any(word in joke_text.lower() for word in tech_words)
    has_emotion = any(word in joke_text.lower() for word in emotion_words)
    
    if has_tech and has_emotion:
        score += 5.0
        key_elements.append("Tech + emotion incongruity")
    
    # B. Formal + informal (firma + piero≈Ñsko, API + wujek)
    formal_words = ['firma', 'api', 'system', 'projekt', 'aplikacja']
    informal_words = ['piero≈Ñsko', 'wujek', 'janusz', '≈Çooo', 'chopie']
    
    has_formal = any(word in joke_text.lower() for word in formal_words)
    has_informal = any(word in joke_text.lower() for word in informal_words)
    
    if has_formal and has_informal:
        score += 3.0
        key_elements.append("Formal + informal language")
    
    # C. Temporal incongruity (2025 + stare tech, przysz≈Ço≈õƒá + polonez)
    year_pattern = r'20\d{2}'
    old_tech = ['polonez', 'fiat', 'windows vista', 'faks']
    
    has_year = re.search(year_pattern, joke_text)
    has_old = any(word in joke_text.lower() for word in old_tech)
    
    if has_year and has_old:
        score += 2.0
        key_elements.append("Temporal incongruity")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Incongruity detected: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Patterns szukane:**
- Tech + emotion (AI + by≈Ça)
- Formal + informal (API + wujek)
- Temporal (2025 + polonez)
- Semantic opposites (inteligentna + error 404)

**Problem (z test√≥w):**
‚ùå **Zbyt restrykcyjne patterns** - "error 404: brain not found" dostaje 0.0/10!

**Do poprawy:**
- Dodaƒá "error + [concept]" pattern
- Dodaƒá wiƒôcej tech-human combinations
- Dodaƒá semantic similarity check (word embeddings)

---

### 3. Semantic Shift Analyzer

**Cel:** Wykryƒá przesuniƒôcie znaczenia (gra s≈Ç√≥w, double meaning)

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    
    score = 0.0
    key_elements = []
    
    # A. Homonyms/polysemy (formularz = form + relationship)
    # U≈ºywa word embeddings do wykrycia wieloznaczno≈õci
    
    # B. Brand names used differently (Octadecimal = tabletki)
    capitalized_words = [token.text for token in doc if token.is_title]
    
    if len(capitalized_words) > 0:
        for word in capitalized_words:
            # Check if used metaphorically
            if 'brzmi jak' in joke_text.lower():
                score += 2.0
                key_elements.append(f"Metaphorical use: {word}")
    
    # C. Tech jargon repurposed (AI = sztuczna inteligencja babƒá)
    tech_jargon = ['ai', 'automatyzacja', 'api', 'algorithm']
    mundane_context = ['bazar', 'babcia', 'og√≥rek', 'piwnica']
    
    has_jargon = any(word in joke_text.lower() for word in tech_jargon)
    has_mundane = any(word in joke_text.lower() for word in mundane_context)
    
    if has_jargon and has_mundane:
        score += 3.5
        key_elements.append("Tech jargon in mundane context")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Semantic shift: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Patterns szukane:**
- Metaphors (brzmi jak, to jak)
- Tech in mundane context
- Capitalized words repurposed

---

### 4. Timing Analyzer

**Cel:** Wykryƒá rytm, tempo, pauzowanie

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    sentences = list(doc.sents)
    
    score = 0.0
    key_elements = []
    
    # A. Sentence length variation (kr√≥tkie + d≈Çugie)
    if len(sentences) >= 2:
        lengths = [len(str(s)) for s in sentences]
        variation = max(lengths) / (min(lengths) + 1)
        
        if variation > 2.0:
            score += 3.0
            key_elements.append(f"Length variation: {variation:.1f}x")
    
    # B. Ellipsis (...) - pause marker
    if '...' in joke_text:
        score += 2.5
        key_elements.append("Ellipsis pause")
    
    # C. Question before answer (setup timing)
    if '?' in joke_text:
        question_idx = joke_text.index('?')
        remaining = joke_text[question_idx:]
        if len(remaining) > 10:
            score += 2.0
            key_elements.append("Question-answer timing")
    
    # D. Staccato rhythm (short sentences)
    if len(sentences) >= 3:
        short_count = sum(1 for s in sentences if len(str(s)) < 30)
        if short_count >= 2:
            score += 1.5
            key_elements.append(f"Staccato: {short_count} short sentences")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Timing mechanics: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Markers szukane:**
- Sentence length variation
- Ellipsis (...)
- Question-answer structure
- Staccato rhythm (short sentences)

---

### 5. Absurd Escalation Analyzer

**Cel:** Wykryƒá eskalacjƒô absurdu (normalne ‚Üí dziwne ‚Üí kompletnie absurdalne)

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    
    score = 0.0
    key_elements = []
    
    # A. Progression markers (dalej, p√≥≈∫niej, jeszcze, coraz)
    progression = ['dalej', 'p√≥≈∫niej', 'jeszcze', 'coraz', 'nawet']
    count = sum(1 for word in progression if word in joke_text.lower())
    
    if count > 0:
        score += count * 1.5
        key_elements.append(f"Progression markers: {count}")
    
    # B. Absurd combinations detected by incongruity
    # (babcie + AI, telepatyczne API, automat z piwem = automatyzacja)
    
    absurd_combinations = [
        (['babcia', 'babcie'], ['ai', 'sztuczna inteligencja']),
        (['telepatyczny', 'telepatyczne'], ['api', 'interfejs']),
        (['automat'], ['piwo', 'reszta']),
    ]
    
    for combo in absurd_combinations:
        has_all = all(
            any(word in joke_text.lower() for word in group)
            for group in combo
        )
        if has_all:
            score += 2.0
            key_elements.append(f"Absurd combo: {combo}")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Absurd escalation: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Patterns szukane:**
- Progression words (jeszcze, nawet, coraz)
- Absurd combinations (babcie + AI)
- Escalating comparisons

**Problem (z test√≥w):**
‚ùå **Nie wykrywa wiƒôkszo≈õci absurd√≥w** - "babcie handlujƒÖ AI" dostaje 1.5/10

---

### 6. Psychoanalysis Analyzer

**Cel:** Wykryƒá frustracjƒô, strach, pragnienia (Freud)

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    
    score = 0.0
    key_elements = []
    
    # A. Frustration markers
    frustration = ['niestety', 'znowu', 'kolejny', 'pewnie', 'chyba']
    count = sum(1 for word in frustration if word in joke_text.lower())
    
    if count > 0:
        score += count * 1.0
        key_elements.append(f"Frustration: {count} markers")
    
    # B. Relationship trauma (by≈Ça, ex, rozstanie)
    trauma = ['by≈Ça', 'by≈Çy', 'ex-', 'rozstanie', 'zdrada']
    has_trauma = any(word in joke_text.lower() for word in trauma)
    
    if has_trauma:
        score += 2.5
        key_elements.append("Relationship trauma")
    
    # C. Tech anxiety (nie dzia≈Ça, b≈ÇƒÖd, error)
    anxiety = ['nie dzia≈Ça', 'b≈ÇƒÖd', 'error', 'wywala siƒô', 'nie odpowiada']
    has_anxiety = any(phrase in joke_text.lower() for phrase in anxiety)
    
    if has_anxiety:
        score += 2.0
        key_elements.append("Tech anxiety")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Psychoanalysis: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Themes szukane:**
- Frustration (niestety, znowu)
- Relationship trauma (by≈Ça, ex)
- Tech anxiety (error, nie dzia≈Ça)
- Authority rebellion (system, firma)

---

### 7. Archetype Analyzer

**Cel:** Wykryƒá polskie archetypy (Janusz, wujek ze ≈ölƒÖska, Sosnowiec)

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    
    score = 0.0
    key_elements = []
    
    # A. Regional archetypes
    regional = {
        '≈õlƒÖski': ['≈õlƒÖzok', 'wujek ze ≈õlƒÖska', 'wongiel', '≈Çooo panie'],
        'sosnowiec': ['sosnowiec', 'sosnowca', 'tworki'],
        'warszawa': ['warszawa', 'warszawiak'],
    }
    
    for region, keywords in regional.items():
        if any(kw in joke_text.lower() for kw in keywords):
            score += 2.5
            key_elements.append(f"Regional: {region}")
    
    # B. Character archetypes
    characters = {
        'janusz': ['janusz', 'janusze'],
        'gra≈ºyna': ['gra≈ºyna', 'karyna'],
        'wujek': ['wujek', 'stryj'],
    }
    
    for char, keywords in characters.items():
        if any(kw in joke_text.lower() for kw in keywords):
            score += 2.0
            key_elements.append(f"Character: {char}")
    
    # C. Cultural references
    culture = ['biedronka', 'ikea', 'polonez', 'fiat 126p', 'kebab']
    found = [ref for ref in culture if ref in joke_text.lower()]
    
    if found:
        score += len(found) * 1.5
        key_elements.append(f"Cultural: {', '.join(found)}")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Polish archetypes: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Archetypes szukane:**
- Regional: ≈ölƒÖzok, Sosnowiec, Tworki
- Characters: Janusz, Gra≈ºyna, wujek
- Cultural: Biedronka, IKEA, Polonez

**Problem (z test√≥w):**
‚ùå **Nie wykrywa wiƒôkszo≈õci** - "wujek ze ≈ölƒÖska" dostaje 2.5/10

**Do poprawy:**
- Dodaƒá wiƒôcej keywords
- Zwiƒôkszyƒá wagi (2.5 ‚Üí 5.0)
- Dodaƒá contextualization (≈ölƒÖsk + wongiel)

---

### 8. Humor Atoms Analyzer

**Cel:** Wykryƒá mikro-komponenty (emoji, wykrzykniki, onomatopeje)

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    
    score = 0.0
    key_elements = []
    
    # A. Emoji count
    emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF]'
    emojis = re.findall(emoji_pattern, joke_text)
    
    if len(emojis) > 0:
        score += min(len(emojis) * 0.9, 3.0)
        key_elements.append(f"Emojis: {len(emojis)}")
    
    # B. Exclamation marks
    exclamations = joke_text.count('!')
    if exclamations > 0:
        score += min(exclamations * 0.5, 2.0)
        key_elements.append(f"Exclamations: {exclamations}")
    
    # C. Onomatopoeia (haha, xd, lol)
    sounds = ['haha', 'hehe', 'xd', 'lol', 'rofl']
    found = [s for s in sounds if s in joke_text.lower()]
    
    if found:
        score += len(found) * 1.0
        key_elements.append(f"Sounds: {', '.join(found)}")
    
    # D. Capitalization emphasis
    caps_words = [t.text for t in doc if t.text.isupper() and len(t.text) > 2]
    if caps_words:
        score += len(caps_words) * 0.8
        key_elements.append(f"CAPS: {len(caps_words)}")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Humor atoms: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Atoms szukane:**
- Emoji (üòÇ, ü§ñ, üíî)
- Exclamations (!, !!)
- Onomatopoeia (xd, haha)
- CAPS emphasis

---

### 9. Reverse Engineering Analyzer

**Cel:** Odwr√≥ciƒá ≈ºart i sprawdziƒá czy struktura dzia≈Ça bez tre≈õci

**Algorytm:**

```python
def analyze(joke_text, context):
    doc = nlp(joke_text)
    sentences = list(doc.sents)
    
    score = 0.0
    key_elements = []
    
    # A. Multi-part structure (X? Y! / X... ale Y)
    if len(sentences) >= 2:
        score += 3.0
        key_elements.append("Multi-part structure")
    
    # B. Question-statement pattern
    has_question = '?' in joke_text
    has_statement = '.' in joke_text or '!' in joke_text
    
    if has_question and has_statement:
        score += 2.5
        key_elements.append("Q&A pattern")
    
    # C. Comparison structure (jak, to jak, bardziej ni≈º)
    comparisons = ['jak', 'to jak', 'bardziej ni≈º', 'lepiej ni≈º']
    found = [c for c in comparisons if c in joke_text.lower()]
    
    if found:
        score += len(found) * 1.5
        key_elements.append(f"Comparisons: {len(found)}")
    
    # D. List structure (X, Y i Z / ani X ani Y)
    list_markers = [',', ' i ', ' ani ', ' lub ']
    count = sum(1 for m in list_markers if m in joke_text.lower())
    
    if count >= 2:
        score += 2.0
        key_elements.append(f"List structure: {count} markers")
    
    # Max: 10.0
    score = min(score, 10.0)
    
    explanation = f"Structural mechanics: {score:.1f}/10"
    
    return {
        'score': score,
        'explanation': explanation,
        'key_elements': key_elements
    }
```

**Structures szukane:**
- Multi-part (2+ sentences)
- Q&A pattern
- Comparisons (jak, to jak)
- Lists (X, Y i Z)

---

## üìä Scoring i agregacja

### Step 3: Calculate overall score

```python
# Simple weighted average
raw_scores = {theory: score for theory, score in theory_scores.items()}
overall_score = sum(raw_scores.values()) / len(raw_scores)
```

**Obecnie:** Simple average (ka≈ºda teoria = r√≥wna waga)

**Problem:**
- Zbyt niskie scores (2-3/10 dla dobrych ≈ºart√≥w)
- Potrzeba dostrojenia wag

**Do zmiany:**
```python
# Weighted average z priorytetami
weights = {
    'setup_punchline': 0.15,      # Podstawa
    'incongruity': 0.20,          # Kluczowe dla humoru
    'semantic_shift': 0.15,       # Gra s≈Ç√≥w
    'timing': 0.10,               # Tempo
    'absurd_escalation': 0.15,    # Waldus style
    'psychoanalysis': 0.05,       # Mniej wa≈ºne
    'archetype': 0.15,            # Polski context
    'humor_atoms': 0.03,          # Kosmetyka
    'reverse_engineering': 0.02,  # Struktura
}

overall_score = sum(
    raw_scores[theory] * weight 
    for theory, weight in weights.items()
)
```

### Step 4: Segment scoring

```python
# Dla r√≥≈ºnych cel√≥w biznesowych
segment_scores = {
    'reach': calculate_reach_score(raw_scores),
    'viral': calculate_viral_score(raw_scores),
    'monetization': calculate_monetization_score(raw_scores),
}

def calculate_reach_score(raw_scores):
    # Reach = szeroki zasiƒôg (uniwersalne)
    weights = {
        'setup_punchline': 0.35,
        'archetype': 0.30,
        'incongruity': 0.20,
        'timing': 0.15,
    }
    return weighted_sum(raw_scores, weights)
```

---

## üîç Przyk≈Çadowa analiza krok po kroku

### Input

```json
{
  "joke_text": "Automatyzacja z AI? Brzmi jak moja by≈Ça - te≈º twierdzi≈Ça ≈ºe jest inteligentna, a ko≈Ñczy≈Ço siƒô na 'error 404: brain not found' ü§ñüíî"
}
```

### Step 1: Preprocessing (ka≈ºdy analyzer osobno)

```python
nlp = spacy.load('pl_core_news_lg')
doc = nlp(joke_text)

# Tokenization
tokens = [
  'Automatyzacja', 'z', 'AI', '?', 'Brzmi', 'jak', 'moja', 
  'by≈Ça', '-', 'te≈º', 'twierdzi≈Ça', '≈ºe', 'jest', 'inteligentna',
  ',', 'a', 'ko≈Ñczy≈Ço', 'siƒô', 'na', "'", 'error', '404', ':', 
  'brain', 'not', 'found', "'", 'ü§ñ', 'üíî'
]

# Sentences
sentences = [
  "Automatyzacja z AI?",
  "Brzmi jak moja by≈Ça - te≈º twierdzi≈Ça ≈ºe jest inteligentna, a ko≈Ñczy≈Ço siƒô na 'error 404: brain not found' ü§ñüíî"
]

# POS tags
pos_tags = {
  'Automatyzacja': 'NOUN',
  'AI': 'PROPN',
  'by≈Ça': 'NOUN',
  'error': 'NOUN',
  ...
}
```

### Step 2: Theory analysis

#### 1. Setup-Punchline (4.0/10)

```python
# 2 sentences? YES ‚Üí +3.0
# Question separator? YES ('?') ‚Üí +2.0
# Short punchline? NO (sentence 2 is longer)
# Contrast words? NO
# End marker? YES (emoji) ‚Üí +1.0
# SCORE: 3.0 + 2.0 + 1.0 = 6.0
# But implementation m√° bug: dostaje 4.0
```

#### 2. Incongruity (0.0/10) ‚ùå

```python
# Tech + emotion? 
#   has_tech = 'AI' in text? YES
#   has_emotion = 'by≈Ça' in text? YES
#   BUT: 'by≈Ça' nie jest w emotion_words list!
#   ‚Üí NO MATCH
# 
# Formal + informal? NO
# Temporal incongruity? NO
# 
# SCORE: 0.0  ‚ùå TO JEST B≈ÅƒÑD!
# Powinno byƒá: 5.0+ (AI + by≈Ça + error 404)
```

#### 3. Semantic Shift (5.5/10)

```python
# Metaphorical use ('brzmi jak')? YES ‚Üí +2.0
# Tech in mundane? 'AI' + 'by≈Ça' ‚Üí +3.5
# SCORE: 5.5
```

#### 4. Timing (4.0/10)

```python
# Length variation? YES (short + long) ‚Üí +3.0
# Ellipsis? NO
# Question-answer? YES ‚Üí +2.0
# Staccato? NO
# SCORE: 5.0 (limited to implementation)
```

#### 5. Absurd Escalation (0.0/10)

```python
# Progression markers? NO
# Absurd combos? NO (not in predefined list)
# SCORE: 0.0
```

#### 6. Psychoanalysis (0.0/10)

```python
# Frustration? NO
# Relationship trauma? 'by≈Ça' ‚Üí +2.5... but not detected
# Tech anxiety? 'error' ‚Üí +2.0... but not detected
# SCORE: 0.0  ‚ùå Should be ~4.5
```

#### 7. Archetype (0.0/10)

```python
# Regional? NO
# Characters? NO
# Cultural? NO
# SCORE: 0.0
```

#### 8. Humor Atoms (1.0/10)

```python
# Emojis? YES (2) ‚Üí +1.8
# Exclamations? NO
# Onomatopoeia? NO
# CAPS? NO
# SCORE: 1.8 (limited to 1.0 in impl)
```

#### 9. Reverse Engineering (4.5/10)

```python
# Multi-part? YES ‚Üí +3.0
# Q&A pattern? YES ‚Üí +2.5
# Comparisons? 'jak' ‚Üí +1.5
# SCORE: 7.0 (limited to 4.5)
```

### Step 3: Aggregate

```python
raw_scores = {
    'setup_punchline': 4.0,
    'incongruity': 0.0,        # ‚ùå B≈ÅƒÑD
    'semantic_shift': 5.5,
    'timing': 4.0,
    'absurd_escalation': 0.0,  # ‚ùå B≈ÅƒÑD
    'psychoanalysis': 0.0,     # ‚ùå B≈ÅƒÑD
    'archetype': 0.0,
    'humor_atoms': 1.0,
    'reverse_engineering': 4.5,
}

overall_score = sum(raw_scores.values()) / 9 = 19.0 / 9 = 2.11
```

### Step 4: Output

```json
{
  "overall_score": 2.10,
  "theory_scores": {
    "setup_punchline": {
      "score": 4.0,
      "explanation": "Setup-punchline structure detected",
      "key_elements": ["Multiple sentences: 2", "Question separator"]
    },
    "incongruity": {
      "score": 0.0,
      "explanation": "No incongruity detected",
      "key_elements": []
    },
    ...
  }
}
```

---

## üêõ Problemy wykryte w testach

### 1. Incongruity Analyzer - CRITICAL ‚ùå

**Problem:** Nie wykrywa tech-human incongruity

**Przyk≈Çad:**
- "AI" + "by≈Ça" + "error 404: brain not found"
- Powinno: 8-9/10
- Dostaje: 0/10

**Fix:**
```python
# Dodaj do emotion_words
emotion_words = [
    'by≈Ça', 'by≈Çy', 'ex',           # ‚Üê DODAƒÜ
    'mi≈Ço≈õƒá', 'serce', 'uczucia', 
    'romans', 'zwiƒÖzek', 'rozstanie'
]

# Dodaj error patterns
tech_fail_patterns = [
    r'error \d+',                   # ‚Üê DODAƒÜ
    r'404.*not found',
    r'nie znaleziono',
]
```

### 2. Archetype Analyzer - CRITICAL ‚ùå

**Problem:** Nie wykrywa polskich archetyp√≥w

**Fix:**
```python
regional = {
    '≈õlƒÖski': [
        '≈õlƒÖzok', 'wujek ze ≈õlƒÖska', 'wongiel',  # istniejƒÖce
        '≈Çooo panie', '≈Ço panie', 'chopie',      # ‚Üê DODAƒÜ
        'piero≈Ñsko', 'mo', 'kaj'
    ],
    'sosnowiec': [
        'sosnowiec', 'sosnowca', 'tworki',       # istniejƒÖce
        'bazar', 'bazarek'                        # ‚Üê DODAƒÜ
    ],
}

# Zwiƒôksz wagi
score += 5.0  # by≈Ço: 2.5
```

### 3. Overall Scoring - MAJOR ‚ö†Ô∏è

**Problem:** Zbyt niskie scores (2-3/10 dla dobrych ≈ºart√≥w)

**Fix:**
```python
# Zamiast simple average, u≈ºyj weighted
weights = {
    'setup_punchline': 0.15,
    'incongruity': 0.20,      # boost
    'archetype': 0.15,        # boost
    ...
}
```

---

## üîÑ Roadmap ulepsze≈Ñ

### Faza 1: Bug fixes (ASAP)

- [ ] Fix incongruity: tech-human patterns
- [ ] Fix archetype: polskie keywords + wagi
- [ ] Fix overall: weighted average

### Faza 2: ML/AI integration (Q1 2025)

- [ ] Replace regex with fine-tuned BERT
- [ ] Add sentiment analysis (Hugging Face)
- [ ] Use GPT-4o mini for explanation generation

### Faza 3: User feedback loop (Q2 2025)

- [ ] Collect user ratings
- [ ] Train regression model (predicted vs actual)
- [ ] Adjust weights based on data

---

**Autor:** Claude Sonnet 4.5 + Piotras  
**Data:** 2025-11-14  
**Wersja:** 1.0

