# Rekomendacje modeli Ollama dla zadaÅ„ Waldus

## ğŸ¯ Wymagania zadania

- âœ… **Strukturyzowane odpowiedzi JSON** - zÅ‚oÅ¼one formaty z wieloma kategoriami
- âœ… **JÄ™zyk polski** - wysokiej jakoÅ›ci odpowiedzi po polsku
- âœ… **KreatywnoÅ›Ä‡ i sarkazm** - inteligentny humor, przewrotnoÅ›Ä‡
- âœ… **Precyzja** - dokÅ‚adne przestrzeganie formatu i wymagaÅ„

## ğŸ“Š PorÃ³wnanie modeli dla polskiego + JSON

### â­â­â­â­â­ Najlepsze opcje

#### 1. **Qwen2.5 7B/14B** (REKOMENDOWANE dla polskiego)

**Zalety:**
- âœ… **DoskonaÅ‚y dla polskiego** - trenowany na duÅ¼ym korpusie polskich tekstÃ³w
- âœ… **Åšwietny JSON** - bardzo dobre przestrzeganie formatÃ³w
- âœ… **KreatywnoÅ›Ä‡** - dobry balans miÄ™dzy precyzjÄ… a kreatywnoÅ›ciÄ…
- âœ… **WielkoÅ›Ä‡:** 7B Q4 (~4.5GB) lub 14B Q4 (~8GB)

**DostÄ™pne wersje:**
```bash
ollama pull qwen2.5:7b      # 7B - szybki, dobry dla RTX 3060
ollama pull qwen2.5:14b      # 14B - lepszy, ale wolniejszy
ollama pull qwen2.5:32b      # 32B - najlepszy, ale wymaga duÅ¼o VRAM
```

**Dla RTX 3060:** `qwen2.5:7b` lub `qwen2.5:14b` (jeÅ›li zmieÅ›ci siÄ™ w 12GB)

#### 2. **Aya 23 8B/13B** (NAJLEPSZY dla polskiego)

**Zalety:**
- âœ… **Najlepszy dla polskiego** - specjalnie trenowany dla 23 jÄ™zykÃ³w w tym polskiego
- âœ… **Dobry JSON** - solidne przestrzeganie formatÃ³w
- âœ… **WielojÄ™zycznoÅ›Ä‡** - native support dla polskiego

**DostÄ™pne wersje:**
```bash
ollama pull aya:8b           # 8B - dobry balans
ollama pull aya:13b          # 13B - lepszy, ale wolniejszy
```

**Dla RTX 3060:** `aya:8b` (idealny) lub `aya:13b` (jeÅ›li zmieÅ›ci siÄ™)

#### 3. **Llama 3.1 8B** (obecny - dobry, ale sÅ‚abszy polski)

**Zalety:**
- âœ… **DoskonaÅ‚y JSON** - bardzo dobre przestrzeganie formatÃ³w
- âœ… **KreatywnoÅ›Ä‡** - dobry balans
- âš ï¸ **Polski** - dziaÅ‚a, ale nie jest specjalizowany

**Wady:**
- âš ï¸ Czasem gubi siÄ™ w polskim (mieszanie jÄ™zykÃ³w)
- âš ï¸ SÅ‚absze zrozumienie polskich kontekstÃ³w kulturowych

### â­â­â­â­ Dobre opcje

#### 4. **Mistral 7B**

**Zalety:**
- âœ… Dobry JSON
- âœ… Åšredni polski (lepszy niÅ¼ Llama 3.1)
- âœ… Szybki

**Wady:**
- âš ï¸ Nie specjalizowany dla polskiego

#### 5. **Solar 10.7B**

**Zalety:**
- âœ… Dobry dla polskiego
- âœ… Dobry JSON
- âœ… KreatywnoÅ›Ä‡

**Wady:**
- âš ï¸ WiÄ™kszy rozmiar (moÅ¼e byÄ‡ na granicy dla RTX 3060)

### â­â­â­ Åšrednie opcje

#### 6. **Gemma 2 9B**

**Zalety:**
- âœ… Dobry JSON
- âš ï¸ Åšredni polski

**Wady:**
- âš ï¸ SÅ‚abszy dla polskiego niÅ¼ Qwen/Aya

## ğŸ† Finalna rekomendacja

### Dla zadania Waldus (polski + JSON + kreatywnoÅ›Ä‡):

**1. Qwen2.5 7B** â­â­â­â­â­
```bash
ollama pull qwen2.5:7b
```
- Najlepszy balans jakoÅ›ci polskiego i JSON
- ZmieÅ›ci siÄ™ w RTX 3060 (12GB)
- Szybki (~30-40 tok/s)

**2. Aya 8B** â­â­â­â­â­
```bash
ollama pull aya:8b
```
- Najlepszy dla polskiego
- Dobry JSON
- ZmieÅ›ci siÄ™ w RTX 3060

**3. Qwen2.5 14B** â­â­â­â­ (jeÅ›li zmieÅ›ci siÄ™)
```bash
ollama pull qwen2.5:14b
```
- Lepszy niÅ¼ 7B, ale wolniejszy
- Wymaga ~8-9GB VRAM

### PorÃ³wnanie dla Twojego zadania

| Model | Polski | JSON | KreatywnoÅ›Ä‡ | WydajnoÅ›Ä‡ (RTX 3060) | Rekomendacja |
|-------|--------|------|-------------|---------------------|--------------|
| **Qwen2.5 7B** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | ~30-40 tok/s | âœ… **NAJLEPSZY** |
| **Aya 8B** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | ~25-35 tok/s | âœ… **NAJLEPSZY dla polskiego** |
| **Llama 3.1 8B** | â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | ~30-50 tok/s | âš ï¸ Obecny - sÅ‚abszy polski |
| **Mistral 7B** | â­â­â­ | â­â­â­â­ | â­â­â­â­ | ~35-55 tok/s | âš ï¸ Åšredni polski |
| **Qwen2.5 14B** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | ~20-30 tok/s | âœ… JeÅ›li zmieÅ›ci siÄ™ |

## ğŸš€ Szybki test

Przetestuj rÃ³Å¼ne modele:

```bash
# Pobierz Qwen2.5 7B
ollama pull qwen2.5:7b

# Edytuj scripts/ask_ollama.py:
MODEL = "qwen2.5:7b"

# Uruchom test
python scripts/ask_ollama.py
```

## ğŸ’¡ WskazÃ³wki

1. **Dla najlepszego polskiego:** Aya 8B lub Qwen2.5 7B
2. **Dla najlepszego JSON:** Qwen2.5 lub Llama 3.1
3. **Dla balansu:** Qwen2.5 7B (najlepszy kompromis)
4. **Dla szybkoÅ›ci:** Qwen2.5 7B lub Mistral 7B

## ğŸ“ Uwagi

- Llama 3.1 8B (obecny) jest dobry, ale polski moÅ¼e byÄ‡ sÅ‚abszy
- Qwen2.5 ma najlepszy balans jakoÅ›ci polskiego i JSON
- Aya jest najlepszy dla polskiego, ale moÅ¼e byÄ‡ nieco sÅ‚abszy w JSON
- Wszystkie modele 7B-8B zmieszczÄ… siÄ™ w RTX 3060 12GB

---

**Rekomendacja:** Zacznij od **Qwen2.5 7B** - najlepszy balans dla Twojego przypadku uÅ¼ycia! ğŸ¯

