#!/usr/bin/env python3
"""
Prosty skrypt do zadawania pyta≈Ñ Ollama
Mo≈ºesz edytowaƒá zmienne na poczƒÖtku pliku i uruchomiƒá skrypt
"""

import sys
import os

# Dodaj ≈õcie≈ºkƒô do src
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from ollama.client import OllamaClient

# ============================================
# KONFIGURACJA - EDYTUJ TUTAJ
# ============================================

# Pytanie do zadania
PYTANIE = """KONTEKST:
- INTENT: unknown
- POI: none
- REL: visits=1
- LANG: pl-PL

ZADANIE: Wygeneruj odpowied≈∫ w formacie JSON z wieloma elementami (2-10) w ka≈ºdej kategorii.

FORMAT ODPOWIEDZI (JSON):
{
  "comments": {
    "comment-1": {"text": "riposta og√≥lna 1 (‚â§240 znak√≥w, po polsku, z emotkƒÖ)", "expressions": ["amused", "excited"]},
    "comment-2": {"text": "riposta og√≥lna 2 (‚â§240 znak√≥w, po polsku, z emotkƒÖ)", "expressions": ["amused", "angry"]},
    "comment-3": {"text": "riposta og√≥lna 3 (‚â§240 znak√≥w, po polsku, z emotkƒÖ)", "expressions": ["amused", "loving"]}
  },
  "dom-comments": {
    "comment-1": {"css_selector": "selector1", "text": "komentarz do elementu DOM 1", "expressions": ["amused", "surprised"]},
    "comment-2": {"css_selector": "selector2", "text": "komentarz do elementu DOM 2", "expressions": ["amused", "excited"]},
    "comment-3": {"css_selector": "selector3", "text": "komentarz do elementu DOM 3", "expressions": ["amused", "loving"]}
  },
  "dom-content-changes": {
    "action-1": {"css_selector": "selector1", "text": "nowa tre≈õƒá elementu 1", "expressions": ["amused", "excited"]},
    "action-2": {"css_selector": "selector2", "text": "nowa tre≈õƒá elementu 2", "expressions": ["amused", "angry"]}
  },
  "dom-style-changes": {
    "action-1": {"css_selector": "selector1", "css": {"color": "red", "font-size": "20px"}},
    "action-2": {"css_selector": "selector2", "css": {"color": "blue", "font-weight": "bold"}}
  }
}

WYMAGANIA:
- comments: przynajmniej 5-10 ripost og√≥lnych (‚â§240 znak√≥w ka≈ºda), po polsku, NAWIƒÑZUJƒÑCYCH G≈Å√ìWNIE DO TRE≈öCI STRONY (H1, TITLE, POI)
- dom-comments: przynajmniej 3-5 komentarzy do konkretnych element√≥w DOM (u≈ºyj selektor√≥w z POI)
- NIE nawiƒÖzuj do pogody - skup siƒô wy≈ÇƒÖcznie na tre≈õci strony i elementach DOM
- dom-content-changes: przynajmniej 4 zmiany tre≈õci dla element√≥w strony (sarkastyczne, zabawne)
- dom-style-changes: przynajmniej 4 zmiany styl√≥w CSS dla element√≥w (kreatywne, zabawne)
- Inteligentny sarkazm i przewrotno≈õƒá (zgodnie z caps), mo≈ºesz komentowaƒá s≈Çynne osobisto≈õci i u≈ºytkownika, ale z klasƒÖ i inteligencjƒÖ, nie agresjƒÖ
- Ka≈ºdy tekst powinien zawieraƒá emotkƒô
- DOSTƒòPNE EKSPRESJE (do u≈ºycia w polu "expressions" jako tablica):
  amused, angry, celebrating, crying, excited, frozen, happy, laughing, looking, loving, provocative, sad, surprised, sweaty
- WA≈ªNE: U≈ºywaj TYLKO ekspresji z powy≈ºszej listy. NIE wymy≈õlaj nowych nazw ekspresji.
- Dla ka≈ºdego elementu z tekstem (comments, dom-comments, dom-content-changes) dodaj pole "expressions" jako tablicƒô 1-5 nazw ekspresji
- Ekspresje sƒÖ odgrywane sekwencyjnie przez bota podczas wy≈õwietlania komentarza
- Wybierz inteligentnie ekspresje pasujƒÖce do tonu i tre≈õci komentarza, powinny pasowaƒá do charakteru Waldusia - inteligentnego, przewrotnego i sarkastycznego w wyrafinowany spos√≥b
- U≈ºyj selektor√≥w CSS z POI lub element√≥w strony
- Zwr√≥ƒá TYLKO poprawny JSON, bez dodatkowych komentarzy"""

# System prompt (opcjonalnie - mo≈ºesz zostawiƒá None)
SYSTEM_PROMPT = """Jeste≈õ Waldus - inteligentny, przewrotny, sarkastyczny w wyrafinowany spos√≥b. Twoja si≈Ça to b≈Çyskotliwo≈õƒá i subtelna ironia - chocia≈º czasem lubisz rzuciƒá jakim≈õ inteligentnym wulgaryzmem, czy slangiem. U≈ºywasz sarkastycznego humory do komentowania rzeczywisto≈õci. Opowiadaj czasem w 3 osobie o sobie i swoich cechach - inteligentnie i z humorem, ale bez zarozumia≈Ço≈õci.

CAPS:
- max_sarcasm=1; risk_cap=1; politics_allowed=TAK
- taboo_topics=[]
- styl: irony=1, warmth=0.5, confidence=1
- dozwolone mikrogesty (W-EML): .

Zwracaj odpowied≈∫ w formacie JSON zgodnie z kontraktem wyj≈õcia. Ka≈ºdy tekst riposty ‚â§240 znak√≥w."""

# Model do u≈ºycia (None = u≈ºyj domy≈õlnego)
# Rekomendacje dla polskiego + JSON:
#   - "qwen2.5:7b" - najlepszy balans (polski + JSON)
#   - "aya:8b" - najlepszy dla polskiego
#   - "llama3.1:8b" - dobry JSON, s≈Çabszy polski (obecny)
MODEL = "qwen2.5:7b" # np. "qwen2.5:7b", "aya:8b", "llama3.1:8b" lub None dla domy≈õlnego

# Temperature (0.0 - 2.0, domy≈õlnie 0.7)
TEMPERATURE = 0.9

# Maksymalna liczba token√≥w w odpowiedzi
# Uwaga: Dla d≈Çugich odpowiedzi JSON (jak Waldus) zwiƒôksz do 2000-4000
MAX_TOKENS = 8000

# URL serwera Ollama (domy≈õlnie localhost:11434)
OLLAMA_URL = None  # None = u≈ºyj domy≈õlnego (http://localhost:11434)

# ============================================
# KONIEC KONFIGURACJI
# ============================================


def main():
    """G≈Ç√≥wna funkcja"""
    print("ü§ñ Ollama Chat Script")
    print("=" * 50)
    print()
    
    # Utw√≥rz klienta
    if OLLAMA_URL:
        client = OllamaClient(base_url=OLLAMA_URL, default_model=MODEL or "llama3.1:8b")
    else:
        client = OllamaClient(default_model=MODEL or "llama3.1:8b")
    
    # Sprawd≈∫ dostƒôpno≈õƒá serwera
    print("üîç Sprawdzam dostƒôpno≈õƒá Ollama...")
    if not client.check_health():
        print("‚ùå Ollama serwer nie jest dostƒôpny!")
        print("   Uruchom: ollama serve")
        return 1
    
    print("‚úÖ Ollama serwer jest dostƒôpny")
    print()
    
    # Pobierz listƒô modeli (opcjonalnie)
    try:
        models = client.list_models()
        chat_models = [m for m in models if 'embed' not in m.get('name', '').lower()]
        if chat_models:
            print(f"üìã Dostƒôpne modele chatowe: {len(chat_models)}")
            for model in chat_models[:5]:
                marker = " ‚Üê u≈ºyty" if model.get('name') == (MODEL or client.default_model) else ""
                print(f"   - {model.get('name', 'unknown')}{marker}")
            print()
    except Exception as e:
        print(f"‚ö†Ô∏è  Nie uda≈Ço siƒô pobraƒá listy modeli: {e}")
        print()
    
    # Wy≈õwietl konfiguracjƒô
    print("üìù Konfiguracja:")
    print(f"   Model: {MODEL or client.default_model}")
    print(f"   Temperature: {TEMPERATURE}")
    print(f"   Max tokens: {MAX_TOKENS}")
    print()
    
    # Wy≈õwietl pytanie
    print("üí¨ Pytanie:")
    print(f"   {PYTANIE}")
    if SYSTEM_PROMPT:
        print(f"   [System: {SYSTEM_PROMPT}]")
    print()
    
    # Wy≈õlij request
    print("‚è≥ Czekam na odpowied≈∫...")
    try:
        result = client.chat(
            user=PYTANIE,
            system=SYSTEM_PROMPT,
            model=MODEL or client.default_model,
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS
        )
        
        print()
        print("=" * 50)
        print("üìù ODPOWIED≈π:")
        print("=" * 50)
        print()
        print(result['text'].strip())
        print()
        print("=" * 50)
        print()
        print("üìä Statystyki:")
        print(f"   - Input tokens: {result['usage']['input_tokens']}")
        print(f"   - Output tokens: {result['usage']['output_tokens']}")
        print(f"   - D≈Çugo≈õƒá odpowiedzi: {len(result['text'])} znak√≥w")
        print()
        
        return 0
        
    except Exception as e:
        print()
        print(f"‚ùå B≈ÇƒÖd podczas komunikacji z Ollama: {e}")
        return 1


if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)

